# todo Clean importing calls
# Standard Packages
import numpy as np
from math import exp, sqrt, floor
from tifffile import tifffile as tf
import glob
import matplotlib.pyplot as plt
import pandas as pd
import time
from datetime import date
import numpy.ma as ma
import scipy.signal as ss
import scipy.interpolate as interp
from scipy.optimize import curve_fit

from scipy.ndimage import median_filter
from scipy.ndimage import gaussian_filter
from scipy.interpolate import make_interp_spline

import concurrent.futures
from functools import partial

# Image stuff
import matplotlib.patches as patches
from PIL import Image
from skimage.filters import threshold_otsu
from skimage.morphology import closing, square, disk
from skimage.segmentation import clear_border
from skimage.measure import label, regionprops_table
from skimage import util, draw

# Multiprocessing
import os
from multiprocessing.dummy import Pool as ThreadPool

# Configuration File
from gued_globals import *


### Reading Images Functions

# todo learn about classes and figure out how to implement

def get_counts(data_array, plot=False):  # todo clean and update
    """
    Generates the counts from the given data by summing over the array elements. Returns 2d array of the same dimension as the
    input images.

    Arguments:

    data_array (numpy.ndarray): Numpy data array containing the diffraction images.
    plot (bool, optional): If set to true, generates a graph of the counts data.

    Returns:
    counts (numpy.ndarray): One dimensional numpy array containing the data after summing over each array element.

    Example:

    data = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])
    >>>countData(data)
        array([21, 51])
    """
    counts = np.sum(data_array, axis=(1, 2))
    if len(data_array) == 0:
        raise ValueError("Input data_array is empty.")
    if data_array.ndim != 3:
        raise ValueError("Input data_array is not 3 dimensional.")
    if plot == True:
        plt.plot(np.arange(len(data_array[:, 0, 0])), counts)
        plt.show()
    return counts


def get_image_details(file_names, sort=True, plot=False,
                      filter_data=False):  # looks pretty good for now todo look into optional arguments
    """
    Returns the data loaded from the tif files with a floor subtracted based on the median of the corner. Also returns arrays with the stage
    positions, the file order number, and the number of counts per image.

    Arguments:
    data_array (numpy.ndarray): Numpy data array containing the diffraction images.
    file_names = ['image001_10.tif', 'image002_20.tif', 'image004_40.tif', 'image003_30.tif', 'image004_40.tif']

    Optional arguments:
    sort (boolean): default is set to True. This arguments sorts the data based on when it was saved (i.e. file number)
    plot (boolean): default is set to False. When True, a plot of the data, log(data), and histogram of counts is shown
    filter_data (boolean): default is set to False. When True, code prompts you for a minimum and maximum value then
        returns only the information from files within this range

    Returns:
    data_array (ndarray): Array of N x 1024 x 1024 where N is the length of tile file_names list. Generated by using tifffile as tf.
    stage_pos (array): Default. A numpy array containing the stage positions of the file. The index of each stage position corresponds to
                            the index of the file name in file_names.
    file_order (array): Returns the image number located in the file name. Reflects the order with which the images are taken.
    counts(ndarray): One dimensional numpy array of length N containing the data after summing over each array element.

    """
    data_array = tf.imread(file_names)  # construct array containing files

    try:
        stage_pos = []
        file_order = []
        try:
            # stage_pos = [np.float64(file_name[idx_start:idx_end]) for file_name in file_names]
            # stage_pos = np.array(stage_pos)
            for file in file_names:
                string = list(
                    map(str, file.split("\\")))  # Note standard slash usage for windows todo might need to test
                folder_number = string[-3][-3:]
                string = list(map(str, string[-1].split("-")))
                file_number = int(folder_number + string[1])
                file_order.append(int(file_number))
                string = list(map(str, string[-1].split("_")))
                stage_pos.append(float(string[0]))
        except ValueError:
            raise ValueError("""Failed to convert a file name to a float. Make sure that index positions are correct for all files in file_names. 
            Also check separators""")
    except IndexError:
        raise ValueError(
            "Invalid index values. Make sure the index values are within the range of the file name strings.")

    stage_pos = np.array(stage_pos)
    file_order = np.array(file_order)
    counts = get_counts(data_array)

    if sort == True:
        idx_sort = np.argsort(file_order)
        file_order = file_order[idx_sort]
        data_array = data_array[idx_sort]
        stage_pos = stage_pos[idx_sort]
        counts = counts[idx_sort]

    if filter_data == True:
        min_val = int(input("Enter minimum file number: "))
        max_val = int(input("Enter maximum file number: "))
        try:
            good_range = np.arange(min_val, max_val, 1)
            data_array = data_array[good_range]
            stage_pos = stage_pos[good_range]
            counts = counts[good_range]
            file_order = file_order[good_range]
        except:
            print("Max value is larger than the size of the data range, returning all data")

    if plot == True:
        test = data_array[0]
        plt.figure(figsize=[12, 10])
        plt.subplot(1, 3, 1);
        plt.imshow(test, cmap='jet');
        plt.xlabel('Pixel');
        plt.ylabel('Pixel');
        plt.title('Linear Scale(data)')

        plt.subplot(1, 3, 2);
        plt.imshow(np.log(test), cmap='jet');
        plt.xlabel('Pixel');
        plt.ylabel('Pixel');
        plt.title('Log Scale(data)')

        plt.subplot(1, 3, 3);
        plt.hist(test.reshape(-1), bins=30, edgecolor="r", histtype="bar", alpha=0.5)
        plt.xlabel('Pixel Intensity');
        plt.ylabel('Pixel Number');
        plt.title('Hist of the pixel intensity(data)');
        plt.yscale('log')
        plt.tight_layout()
        plt.show()

        _show_counts(stage_pos, counts)

    return data_array, stage_pos, file_order, counts


def _show_counts(stage_pos, counts):
    """Function for visualizing and plotting total counts from a set of data. Called within the get_image_details
    function when plot == True"""

    counts_mean = np.mean(counts)  # Mean values of Total Counts of all images
    counts_std = np.std(counts)  # the STD of all the tc for all the iamges
    uni_stage = np.unique(stage_pos)  # Pump-probe stage position
    plt.figure(figsize=(12, 4))  # Plot counts rate, images number at each posi, and bad images

    plt.subplot(1, 3, 1)
    plt.plot(counts, '-d')
    plt.axhline(y=counts_mean, color='k', linestyle='-', linewidth=1, label="mean counts");
    plt.axhline(y=counts_mean - (3 * counts_std), color='r', linestyle='-', linewidth=0.5, label="min counts");
    plt.axhline(y=counts_mean + (3 * counts_std), color='r', linestyle='-', linewidth=0.5, label="max counts");
    plt.xlabel('Images orderd in lab time');
    plt.ylabel('Counts');
    plt.legend()
    plt.title('Total counts');

    plt.subplot(1, 3, 2)  # Histogram the number of images at each posi
    plt.plot(uni_stage, '-o');
    plt.xlabel('pp stage posi');
    plt.ylabel('Stg Position [mm]');
    plt.title('Delay Stage Position');

    plt.subplot(1, 3, 3)  # Histogram the number of images at each posi
    posi_edges_bins = np.append(uni_stage - 0.001, uni_stage[-1])
    posi_hist, posi_edges = np.histogram(stage_pos, bins=posi_edges_bins)
    plt.plot(uni_stage, posi_hist, '-*')
    plt.xlabel('pp stage posi [mm]');
    plt.ylabel('Num of Imges');
    plt.title('Num of images at each delay');

    plt.tight_layout()
    plt.show()


def get_image_details_slac(file_names, sort=True):  # todo update to look like others
    """
    WORKS FOR CURRENT DATA COLLECTION
    Returns the data loaded from the tif files with a floor subtracted based on the median of the corner. Also returns arrays with the stage positions, the
    file order number, and the number of counts per image.

    Arguments:
    data_array (numpy.ndarray): Numpy data array containing the diffraction images.
    file_names = ['image001_10.tif', 'image002_20.tif', 'image004_40.tif', 'image003_30.tif', 'image004_40.tif']

    Returns:
    data_array (ndarray): Array of N x 1024 x 1024 where N is the length of tile file_names list. Generated by using tifffile as tf.
    stage_pos (array): Default. A numpy array containing the stage positions of the file. The index of each stage position corresponds to
                            the index of the file name in file_names.
    file_order (array): Returns the image number located in the file name. Reflects the order with which the images are taken.
    counts(ndarray): One dimensional numpy array of length N containing the data after summing over each array element.

    """
    data_array = tf.imread(file_names)  # construct array containing files

    try:
        stage_pos = []
        file_order = []
        try:
            # stage_pos = [np.float64(file_name[idx_start:idx_end]) for file_name in file_names]
            # stage_pos = np.array(stage_pos)
            for file in file_names:
                string = list(map(str, file.split("/")))
                string = list(map(str, string[-1].split("_")))
                file_order.append(int(string[2]))
                stage_pos.append(float(string[3]))
        except ValueError:
            raise ValueError(
                """Failed to convert a file name to a float. Make sure that index positions are correct for all files in file_names. Also check separators""")
    except IndexError:
        raise ValueError(
            "Invalid index values. Make sure the index values are within the range of the file name strings.")

    stage_pos = np.array(stage_pos)
    file_order = np.array(file_order)
    counts = get_counts(data_array)

    if sort == True:
        idx_sort = np.argsort(file_order)
        file_order = file_order[idx_sort]
        data_array = data_array[idx_sort]
        stage_pos = stage_pos[idx_sort]
        counts = counts[idx_sort]

    return data_array, stage_pos, file_order, counts


def get_image_details_keV(file_names, sort=False, multistage=False):
    # todo update to look like other get_image_details code and make for one stage
    """
    Returns the data loaded from the tif files with a floor subtracted based on the median of the corner. Also returns arrays with the stage
    positions, the file order number, and the number of counts per image.

    Arguments:
    data_array (numpy.ndarray): Numpy data array containing the diffraction images.
    file_names = ['image001_10.tif', 'image002_20.tif', 'image004_40.tif', 'image003_30.tif', 'image004_40.tif']

    Returns:
    data_array (ndarray): Array of N x 1024 x 1024 where N is the length of tile file_names list. Generated by using tifffile as tf.
    stage_pos (array): Default. A numpy array containing the stage positions of the file. The index of each stage position corresponds to
                            the index of the file name in file_names.
    file_order (array): Returns the image number located in the file name. Reflects the order with which the images are taken.
    counts(ndarray): One dimensional numpy array of length N containing the data after summing over each array element.

    """
    data_array = tf.imread(file_names)  # construct array containing files
    if multistage == True:
        try:
            ir_stage_pos = []
            uv_stage_pos = []
            file_order = []
            current = []
            try:
                for file in file_names:
                    string = list(map(str, file.split("/")))
                    string = list(map(str, string[-1].split("_")))
                    file_number = int(string[1])
                    file_order.append(file_number)
                    ir_stage_pos.append(float(string[4]))
                    uv_stage_pos.append(float(string[6]))
                    current.append(float(string[-1][:-5]))
            except ValueError:
                raise ValueError("""Failed to convert a file name to a float. Make sure that index positions are correct for all files in file_names. 
                Also check separators""")
        except IndexError:
            raise ValueError(
                "Invalid index values. Make sure the index values are within the range of the file name strings.")

        ir_stage_pos = np.array(ir_stage_pos)
        uv_stage_pos = np.array(uv_stage_pos)
        file_order = np.array(file_order)
        current = np.array(current)
        counts = get_counts(data_array)

        if sort == True:
            temp_idx = _sort_files_multistage(file_order, ir_stage_pos, uv_stage_pos)
            data_array = data_array[temp_idx]
            ir_stage_pos = ir_stage_pos[temp_idx]
            uv_stage_pos = uv_stage_pos[temp_idx]
            file_order = file_order[temp_idx]
            current = current[temp_idx]
            counts = counts[temp_idx]
        return data_array, ir_stage_pos, uv_stage_pos, file_order, counts, current

    if multistage == False:
        try:
            stage_positions = []
            file_order = []
            current = []
            try:
                for file in file_names:
                    string = list(map(str, file.split("/")))
                    string = list(map(str, string[-1].split("_")))
                    file_number = int(string[1])
                    file_order.append(file_number)
                    stage_positions.append(float(string[4]))
                    current.append(float(string[-1][:-5]))
            except ValueError:
                raise ValueError("""Failed to convert a file name to a float. Make sure that index positions are correct for all files in file_names. 
                Also check separators""")
        except IndexError:
            raise ValueError(
                "Invalid index values. Make sure the index values are within the range of the file name strings.")

        stage_positions = np.array(stage_positions)
        file_order = np.array(file_order)
        current = np.array(current)
        counts = get_counts(data_array)

        if sort == True:
            temp_idx = _sort_files(file_order, stage_positions)
            data_array = data_array[temp_idx]
            stage_positions = stage_positions[temp_idx]
            file_order = file_order[temp_idx]
            current = current[temp_idx]
            counts = counts[temp_idx]

    return data_array, stage_positions, file_order, counts, current


def _sort_files_multistage(file_order, ir_stage_pos, uv_stage_pos):
    uni_stage_ir = np.unique(ir_stage_pos)  # Pump-probe stage position
    uni_stage_uv = np.unique(uv_stage_pos)

    if len(uni_stage_ir) > 1:
        stage_positions = ir_stage_pos
        print("sorting based on IR stage position")
    elif len(uni_stage_uv) > 1:
        stage_positions = uv_stage_pos
        print("sorting based on UV stage position")
    else:
        print("Bad Stage Positions")
    idx_list = []
    uni_stage = np.unique(stage_positions)
    for i in range(len(uni_stage)):
        # file_numbers = file_order[np.where(stage_positions==uni_stage[i])[0]];
        # file_numbers = file_numbers[idx_temp]
        stage_idx = np.where(stage_positions == uni_stage[i])[0]
        file_numbers = file_order[stage_idx]
        idx_temp = np.argsort(file_numbers)
        # print(file_numbers[idx_temp])
        idx_list.append(stage_idx[idx_temp])
    idx_list = np.array(idx_list)
    idx_list = np.reshape(idx_list, len(stage_positions))
    return idx_list


def _sort_files(file_order, stage_positions):
    uni_stage = np.unique(stage_positions)  # Pump-probe stage position

    idx_list = []

    for i in range(len(uni_stage)):
        # file_numbers = file_order[np.where(stage_positions==uni_stage[i])[0]];
        # file_numbers = file_numbers[idx_temp]
        stage_idx = np.where(stage_positions == uni_stage[i])[0]
        file_numbers = file_order[stage_idx]
        idx_temp = np.argsort(file_numbers)
        # print(file_numbers[idx_temp])
        idx_list.append(stage_idx[idx_temp])
    idx_list = np.array(idx_list)
    idx_list = np.reshape(idx_list, len(stage_positions))
    return idx_list


def remove_counts(data_array, stage_positions, file_order, counts, std_factor=3, plot=False):
    """Filters input parameters by removing any data where the total counts falls outside of the set filter. Default
        value is set to 3 standard deviations from the mean. Returns the same variables as it inputs but with
        different dimensions.

        Arguments:
        data_array (ndarray): Multidimensional array of N x 1024 x 1024 where N is the length of file_names list
        stage_pos (array): One dimensional array of length N containing the stage positions associated with each image.
        file_order (array): One dimensional array of length N that reflects the order with which the images are taken.
        counts(ndarray): One dimensional array of length N containing the total counts after summing over each array
        element.

        Optional Arguments:
            std_factor (int): Default value is 3. Refers to cut off based on number of standard deviations from the mean.
            plot (boolean): Default is False. Returns a plot of new and old counts.

        Returns:
            Returns same variables which it received as arguments with new N value."""

    init_length = len(counts)
    # Decide to use threshold or selected images
    counts_mean = np.mean(counts)  # Mean values of Total Counts of all images
    counts_std = np.std(counts)  # the STD of all the tc for all the iamges

    tc_good = np.squeeze(
        np.where(abs(counts - counts_mean) < std_factor * counts_std))  # Find out the indices of the low counts images
    new_array = data_array[tc_good]
    new_stage_positions = stage_positions[tc_good]
    new_counts = counts[tc_good]
    new_file_order = file_order[tc_good]

    print(init_length - len(tc_good), " number of files removed from ", init_length, " initial files")

    if plot == True:
        plt.figure(figsize=(12, 4))  # Plot counts rate, images number at each posi, and bad images

        plt.plot(new_counts, '-d')
        plt.axhline(y=counts_mean, color='k', linestyle='-', linewidth=1, label="mean counts");
        plt.axhline(y=counts_mean - (3 * counts_std), color='r', linestyle='-', linewidth=0.5, label="min counts");
        plt.axhline(y=counts_mean + (3 * counts_std), color='r', linestyle='-', linewidth=0.5, label="max counts");
        plt.xlabel('Images orderd in lab time');
        plt.ylabel('Counts');
        plt.legend()
        plt.title('Total counts');

        plt.tight_layout()
        plt.show()

    return new_array, new_stage_positions, new_file_order, new_counts


### Cleaning Functions

def rmv_xrays_all(data_array, plot=True, std_factor=3):
    """Filters out any pixels that are more than set threshold value based on the standard deviation of the
    average pixel value by running the hidden function _remove_xrays in parallel. If operating on a smaller data set
    use the cleanmean function.

    Arguments:
        data_array (3d array): array of image like data with length N where N is number of images.

    Optional Arguments:
        plot (boolean): Default set to True. Plots the percentage of pixeled removed during cleaning process
        std_factor (int): Default set to 3. Defines the threshold for removing pixels with
        |pixel_value - mean| > std_factor*std

    Returns:
        clean_data (3d array): array of image like data with shape of input data array where errant pixels are now
        masked based on the set threshold"""

    mean_data = np.mean(data_array, axis=0)
    std_data = np.std(data_array, axis=0)
    print("Removing hot pixels from all data")
    clean_data = []
    with concurrent.futures.ThreadPoolExecutor() as executor:
        futures = [executor.submit(partial(_remove_xrays, mean_data, std_data, std_factor), data) for
                   data in data_array]
        results = [future.result() for future in futures]

    clean_data = []
    amt_rmv = []
    for result in results:
        data, amt = result
        clean_data.append(data)
        amt_rmv.append(amt)

    pct_rmv = np.array(amt_rmv) / (len(data_array[1]) * len(data_array[2])) * 100

    if plot == True:
        plt.figure()
        plt.plot(pct_rmv)
        plt.title("Percent Pixels Removed")
        plt.xlabel("Image Number")
        plt.ylabel("Percent")
        plt.show()

    return clean_data


def _remove_xrays(data_array_1d, mean_data, std_data, std_factor=3):
    """This is the hidden function that is run within the rmv_xrays_all function.

    Arguments:
        data_array (2d array): array of image like data with length N where N is number of images.
        mean_data (2d array): average image of all data in data_array from parent function.
        std_data (2d array): image with standard deviation values from all data in data_array in parent function.

    Optional Arguments:
        std_factor (int): Default set to 3. Defines the threshold for removing pixels with
        |pixel_value - mean| > std_factor*std

    Returns:
        clean_data (2d array): array of image like data with shape of input data array where errant pixels are now
        masked based on the set threshold
        amt_rmv (int): count of all pixels removed per image"""

    upper_threshold = mean_data + std_factor * std_data
    clean_data = ma.masked_greater_equal(data_array_1d, upper_threshold)
    amt_rmv = np.sum(clean_data.mask)
    return clean_data, amt_rmv


def cleanMean(data_array, std_factor=4, return_clean_data=True):
    """
    Takes in a data array and calculate the mean and standard deviation at each index across all images. Then applies a filter
    to the data that masks all values (replaces outliers with nan's) outside a given number of standard deviations. After, the
    mean is taken, returning a 2 dimensional array with the mean data of non-outlier entries across all images.

    If return_clean_data is set to True, the cleaned data is returned as a 3d array without having the mean taken.

    Arguments:

    data_array (numpy.ndarray): Data array containing diffraction image data.
    std (int or float): Number of standard deviations from the mean allowed. Values outside this number of standard deviations
                        are masked as nan's. Set to 3 by default.

    Returns:

    clean_mean_data (numpy.ndarray): Default. Returns a 2 dimensional array containing the mean values of the cleaned data.
    clean_data (numpy.ndarray): Other option. Returns the raw 3 dimensional array containing the cleaned data.

    Examples:

    example_array = np.array([[[8.,2],[1,2]], [[1.,2],[1,2]], [[1.,2],[1,2]], [[1., 2], [1,2]]])

    >>> cleanMean(example_array, std_factor=1)
        np.array([[1.,2],[1.,2]])

    >>> cleanMean(example_array, std_factor=1, return_clean_data = True)
        np.array([[[np.nan, 2],[1,2]], [[1.,2],[1,2]], [[1.,2],[1,2]], [[1.,2],[1,2]]])
    """
    if len(data_array) == 0:
        raise ValueError("Input data array is empty.")
    if data_array.ndim != 3:
        raise ValueError("Input data array is not 3 dimensional.")
    if std_factor <= 0:
        raise ValueError("Number of standard deviations (std) must be non-negative.")
    if not isinstance(return_clean_data, bool):
        raise TypeError("return_clean_data must be a boolean value.")

    mean = np.mean(data_array, axis=0)
    stDev = np.std(data_array, axis=0)
    upper_threshold = mean + std_factor * stDev
    # lower_threshold = mean - std*stDev
    clean_data = ma.masked_greater_equal(data_array, upper_threshold)
    # clean_data = ma.masked_outside(data_array, lower_threshold, upper_threshold)
    pct_rmv = []
    for i in range(len(clean_data)):
        no_rmv = sum(sum(clean_data[i].mask))
        pct_rmv.append(no_rmv / (1024 * 1024) * 100)

    pct_rmv = np.array(pct_rmv)
    plt.figure()
    plt.plot(pct_rmv)
    plt.title("Percent Pixels Removed")
    plt.xlabel("Image Number")
    plt.ylabel("Percent")
    plt.show()
    if return_clean_data == True:
        return clean_data
    else:
        clean_mean_data = np.mean(clean_data, axis=(0))
        return clean_mean_data


def medianFilter(data_array, center_top_left_corner, center_border_length,
                 med_filter_range=3):  # todo test and optimize
    """
    Takes in a data array and applies scipy.signal's median filter. Then replaces the boundary and center values with the
    original values from the input array as to not lose precision in these parts.

    Arguments:

    data_array (np.array): 2d Numpy array containing diffraction image data.
    center_top_left_corner (tuple): Tuple containing the row index (integer) and column index (integer) of the top left corner
                                    (lowest_index_row, lowest_index_column)
    center_border_length (int): Length of one side of the square. Must be an integer.
    med_filter_range (int): Must be odd. Initially set to 3. Shape of the square array for median filtering. Using an odd values makes it so that
    the median filter is centered around the individual point.

    Returns:

    med_filt_data (2d-array): Array containing the median filtered data.

    """
    if not isinstance(data_array, np.ndarray):
        raise ValueError("Input data_array must be a 2D numpy array.")
    if not isinstance(center_top_left_corner, tuple) or len(center_top_left_corner) != 2:
        raise ValueError("Center top left corner must be a tuple of length 2 that contains two integers.")
    if not isinstance(center_border_length, int):
        raise ValueError("center_border_length must be an integer.")
    # if not isinstance(center_top_left_corner[0] + center_border_length < data_array[0,-1]
    if not (0 <= center_top_left_corner[0] < data_array.shape[0] and
            0 <= center_top_left_corner[1] < data_array.shape[1] and
            center_top_left_corner[0] + center_border_length <= data_array.shape[0] and
            center_top_left_corner[1] + center_border_length <= data_array.shape[1]):
        raise ValueError("""center_top_left_corner is out of bounds or adding center_border_length goes beyond the array.
                     Check that the tuple values are positive integers within the bounds of the data array and that 
                     adding the border length does not result in a value beyond the size of the array.""")
    if not isinstance(med_filter_range, int) and med_filter_range % 2 == 1:
        raise ValueError("med_filter_range must be an odd integer.")

    med_filt_data = ss.medfilt2d(data_array, med_filter_range)
    med_filt_data[0:med_filter_range // 2, :] = data_array[0:med_filter_range // 2, :]
    med_filt_data[-(med_filter_range // 2):0, :] = data_array[-(med_filter_range // 2):0, :]
    med_filt_data[:, 0:med_filter_range // 2] = data_array[:, 0:med_filter_range // 2]
    med_filt_data[:, -(med_filter_range // 2):] = data_array[:, -(med_filter_range // 2):]
    row_s, col_s = center_top_left_corner
    row_e, col_e = row_s + center_border_length, col_s + center_border_length
    med_filt_data[row_s:row_e, col_s:col_e] = data_array[row_s:row_e, col_s:col_e]
    return med_filt_data


def remove_background(data_array, remove_noise=True, plot=False, print_status=True):
    """
    Takes in a 2d data array (using the mean array is recommended) and calculates the means of the corners. Linearly
    interpolates values across 2d array to generate of background noise values using pandas.DataFrame.interpolate.

    Arguments:
        data_array (3d ndarray): single image array

    Optional Arguments:
        remove_noise (boolean): Default set to true, returns image with background subtracted. If false, returns
        interpolated background.
        plot (boolean): Default set to False. Plots images showing the original image, interpolated background, and
        background subtracted image.
        print_status (boolean): Default set to True. Prints a status update every nth image (n defined via CHECK_NUMBER).

    Global Variables:
        CORNER_RADIUS (int): defines the size of the corners being used in background suptraction.
        CHECK_NUMBER (int): defines how often updates are given when print_status == True

    Returns:
        clean_data (3d ndarray): Returns array of images with background subtracted if remove_noise == True, else returns
        array of interpolated background.
    """
    if not isinstance(data_array, np.ndarray):
        raise ValueError("Input data_array must be a numpy array.")
    if not isinstance(CORNER_RADIUS, int) and CORNER_RADIUS > 0:
        raise ValueError("bkg_range must be an integer > 0.")
    if not isinstance(remove_noise, bool):
        raise ValueError("remove_noise must be a boolean.")
    if not (2 * CORNER_RADIUS < len(data_array[:, 0, :]) and
            2 * CORNER_RADIUS < len(data_array[:, :, 0])):
        raise ValueError("2 * bkg-range must be less than both the number of rows and the number of columns.")

    clean_data = []
    bkg_data = []
    for i, image in enumerate(data_array):
        empty_array = np.empty(np.shape(image))
        empty_array = (ma.masked_array(empty_array, mask=True))
        empty_array[0, 0] = np.mean(image[0:CORNER_RADIUS, 0:CORNER_RADIUS])
        empty_array[-1, 0] = np.mean(image[-CORNER_RADIUS:, 0:CORNER_RADIUS])
        empty_array[0, -1] = np.mean(image[0:CORNER_RADIUS, -CORNER_RADIUS:])
        empty_array[-1, -1] = np.mean(image[-CORNER_RADIUS:, -CORNER_RADIUS:])
        empty_array = pd.DataFrame(empty_array).interpolate(axis=0)
        empty_array = pd.DataFrame(empty_array).interpolate(axis=1)
        bkg = pd.DataFrame.to_numpy(empty_array)
        bkg_data.append(bkg)
        clean_data.append(image - bkg)
        if print_status == True:
            if i % CHECK_NUMBER == 0:
                print(f"Subtracting background of {i}th image.")

    if plot == True:
        plt.figure()

        plt.subplot(1, 3, 1)
        plt.imshow(data_array[0])
        plt.colorbar()
        plt.title("Original Data")

        plt.subplot(1, 3, 2)
        plt.imshow(bkg_data[0])
        plt.colorbar()
        plt.title("Interpolated Background")

        plt.subplot(1, 3, 3)
        plt.imshow(clean_data[0])
        plt.colorbar()
        plt.title("Background Free Data")
        plt.show()

    if remove_noise == True:
        return clean_data
    else:
        return bkg_data


# Masking and Center Finding Functions

def detectorMask(data_array, hole_center, inner_radius, outer_radius,
                 plot_image=True):  # todo figure out which masking to use
    """
    Takes in a 2d data array and applies a circular (donut shaped) detector mask to it, replacing the masked values with np.nan's.
    Returns the masked, 2d data array.

    Arguments:

    data_array (2d np.ndarray): 2d data array to be masked.
    hole_center (tuple): Tuple containing the x and y coordinates of the center of the image, each one of which an int.
    inner_radius (float): Inner radius. Values within the radius of this drawn from the center are masked.
    outer_radius (float): Outer radius of the donut. Values outside the radius of this drawn from the center are masked.
    plot_image (bool, optional): If True, plots the masked image. Default is False.

    Returns:
    ring_data (2d np.ndarray): Data array with the circular detector mask applied.
    """
    if not isinstance(hole_center, tuple) or len(hole_center) != 2:
        raise ValueError(
            "hole_center must be a tuple of length 2 containing the x and y coordinates of the hole center.")
    if not (isinstance(inner_radius, (int, float)) and inner_radius > 0):
        raise ValueError("inner_radius must be a positive float or integer.")
    if not (isinstance(outer_radius, (int, float)) and outer_radius > 0):
        raise ValueError("outer_radius must be a positive float or integer.")
    if inner_radius >= outer_radius:
        raise ValueError("inner_radius must be smaller than outer_radius.")

    hole_cx, hole_cy = hole_center
    x_idx, y_idx = np.meshgrid(np.arange(data_array.shape[2]), np.arange(data_array.shape[1]))
    dist = np.sqrt(((x_idx - hole_cx) ** 2 + (y_idx - hole_cy) ** 2))
    mask = np.logical_and(dist <= outer_radius, dist >= inner_radius)
    ring_data = []
    for i in range(len(data_array)):
        data = np.where(mask, data_array[i], np.nan)
        ring_data.append(data)

    ring_data = np.array(ring_data)
    if plot_image == True:
        img3 = plt.imshow(ring_data[0])
        plt.colorbar(img3)
    return (ring_data)


def mask_generator_alg(data_array_1d, mask_center, mask_radius, fill_value=np.nan, add_mask=[], add_rectangular=False):
    """
    Generate mask to cover unwanted area

    Parameters
    ----------
    data_array_1d : 2D array
        Diffraction pattern.
    mask_center : 1D array, tuple, or list that contains only two values
        Center for generating mask cover unscattered electron beam.
    mask_radius : int
        Radius of the mask.
    fill_value : int, float, or nan, optional
        Value that use to fill the area of the mask. The default is np.nan.
    add_mask : list of 3-value-lists, optional
        Additional masks. Input gonna be [[x-center, y-center, radius], [...], ...] The default is [].
    add_rectangular : boolean, optional
        Additional mask with rectangular shape. The default is True.
    showingfigure : boolean, optional
        Show figure of the result of applied masks. The default is False.

    Returns
    -------
    mask : binary 2D array
        Result of all the masks in an image.

    """

    mask = np.ones(data_array_1d.shape)
    rows, cols = draw.disk((mask_center[1], mask_center[0]), mask_radius, shape=mask.shape)
    mask[rows, cols] = fill_value

    if len(add_mask) == 0:
        pass
    else:
        for i in add_mask:
            rows, cols = draw.disk((i[1], i[0]), i[2], shape=mask.shape)
            mask[rows, cols] = fill_value

    # retangular mask
    if add_rectangular == True:
        rr, cc = draw.rectangle((0, 590), extent=(500, 40), shape=data_array_1d.shape)  # (0,535) for iodobenzene
        mask[rr, cc] = fill_value
        # 515

    return mask


def apply_mask(data_array, mask_center, mask_radius, fill_value=np.nan, add_mask=[], add_rectangular=False,
               plot=False): # todo change mask parameters to global variables
    """ Applies a mask to individual images in the data array.

    Arguments:
        data_array_1d : 2D array
            Diffraction pattern.
        mask_center : 1D array, tuple, or list that contains only two values
            Center for generating mask cover unscattered electron beam.
        mask_radius : int
            Radius of the mask.

    Optional Arguments:
        fill_value : int, float, or nan, optional
            Value that use to fill the area of the mask. The default is np.nan.
        add_mask : list of 3-value-lists, optional
            Additional masks. Input gonna be [[x-center, y-center, radius], [...], ...] The default is [].
        add_rectangular : boolean, optional
            Additional mask with rectangular shape. The default is True.
        showingfigure : boolean, optional
            Show figure of the result of applied masks. The default is False.

    Returns:
        mask : binary 2D array
            Result of all the masks in an image.

    """
    mean_data = np.nanmean(data_array, axis=0)
    masked_data = data_array*mask_generator_alg(mean_data, mask_center, mask_radius, fill_value, add_mask,
                                                add_rectangular)
    masked_mean = np.nanmean(masked_data, axis=0)

    print(masked_data.shape)
    if plot == True:
        fig, axs = plt.subplots(1, 3, figsize=(15, 5))

        # First subplot: Mean of Unmasked Data Array
        axs[0].imshow(mean_data)
        axs[0].set_title("Mean of Unmasked Data Array")
        cbar = plt.colorbar(axs[0].imshow(mean_data), ax=axs[0])
        cbar.ax.set_ylabel('Intensity')

        # Second subplot: Mean of Masked Data Array
        axs[1].imshow(masked_mean)
        axs[1].set_title("Mean of Masked Data Array")
        cbar = plt.colorbar(axs[1].imshow(masked_mean), ax=axs[1])
        cbar.ax.set_ylabel('Intensity')

        # Third subplot: Contour map of average data
        x = np.arange(300, 700)
        y = np.arange(300, 700)
        X, Y = np.meshgrid(y, x)
        pc = axs[2].pcolormesh(x, y, np.log(masked_mean[300:700, 300:700]), shading='auto')
        cs = axs[2].contour(X, Y, np.log(masked_mean[300:700, 300:700]), levels=20, colors='w')
        axs[2].set_title('Contour map of average data')
        cbar = fig.colorbar(pc, ax=axs[2])
        cbar.ax.set_ylabel('Log(Intensity)')

        # Adjust layout to prevent overlap
        plt.tight_layout()

        # Show the combined figure
        plt.show()


    return masked_data


def finding_center_alg(data_array, plot=False, title='Reference Image', thresh_input=0):
    """
    Algorithm for finding the center of diffraction pattern

    Parameters
    ----------
    data_array : 2D array
        Diffraction pattern.
    DISK_RADIUS : int, optional
        Generates a flat, disk-shaped footprint. The default is 3.
    plot : boolean, optional
        Show figure of the result of center finding. The default is False.
    CENTER_GUESS : tuple contains 2 values, optional
        Guessing center position to generate temporary mask. The default is (532, 520).
    RADIUS_GUESS : int, optional
        Guessing radius of the temporary mask. The default is 80.
    title : str, optional
        Title of the figure. The default is 'Reference image'.

    Returns
    -------
    center_x : int
        Center value on x axis.
    center_y : int
        Center value of y axis.
    radius : int
        Radius of ring used for finding center.

    """

    if thresh_input == 0:
        thresh = threshold_otsu(data_array)
    else:
        thresh = thresh_input

    cxt, cyt = [], []
    for th in [1]:
        thresh *= th
        mask_temp = mask_generator_alg(data_array, CENTER_GUESS, RADIUS_GUESS * th, fill_value=False, add_mask=[],
                                       add_rectangular=False)
        mask_temp = util.invert(mask_temp.astype(bool))
        bw = closing(data_array > thresh, disk(
            DISK_RADIUS))  # Return grayscale morphological closing of an image. Square(): generate the footprint to close the gap between data points
        cleared = clear_border(bw + mask_temp)
        label_image = label(cleared)
        props = regionprops_table(label_image, properties=('centroid',
                                                           'axis_major_length',
                                                           'axis_minor_length'))
        dia = np.array([props['axis_major_length'], props['axis_minor_length']])
        dia = np.mean(dia, axis=0)
        radius = np.amax(dia) / 2
        idx = np.where(dia == np.amax(dia))[0][0]
        cxt.append(props['centroid-1'][idx])
        cyt.append(props['centroid-0'][idx])

    center_x = np.mean(cxt)
    center_y = np.mean(cyt)

    if plot == True:
        fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(20, 10))
        ax1.imshow(data_array)
        ax2.imshow(label_image)
        ax3.imshow(bw)

        for cc in range(len(cxt)):
            circ = patches.Circle((cxt[cc], cyt[cc]), radius, linewidth=1, edgecolor="r", facecolor="none",
                                  linestyle='--')
            ax1.add_patch(circ)
            circ = patches.Circle((cxt[cc], cyt[cc]), radius, linewidth=2, edgecolor="r", facecolor="none")
            ax2.add_patch(circ)
            circ = patches.Circle((cxt[cc], cyt[cc]), radius, linewidth=2, edgecolor="r", facecolor="none")
            ax3.add_patch(circ)

        for ax in (ax1, ax2, ax3):
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)
        ax1.set_title(title, fontsize=20)
        ax2.set_title("Center [X = " + str(center_x) + ", Y = " + str(center_y) + "]", fontsize=20)
        ax3.set_title("Binary image", fontsize=20)

        ax1.axvline(center_x, linestyle='--', lw=1, color='tab:red')
        ax1.axhline(center_y, linestyle='--', lw=1, color='tab:red')

        ax2.axvline(center_x, linestyle='--', lw=2, color='tab:red')
        ax2.axhline(center_y, linestyle='--', lw=2, color='tab:red')

        plt.tight_layout()
        plt.show()

    return center_x, center_y, radius, thresh


def find_center_parallel(data_array, plot=True, print_stats=True):
    """ Finds center of each image in the data array using concurrent.futures.ThreadPoolExecutor to quickly process
    many data files.

    Arguments:
        data_array (ndarray): array of image like data with shape Nx1024x1024

    Optional Arguments:
        plot (boolean): Default is set to True. When true, plots an image of the values for center_x and center_y
        with respect to pixel number
        print_stats (boolean): Default is set to True. Prints the average value for center_x and center_y and prints
        the percent failure rate.

    Global Variables Used:
        CENTER_GUESS (tuple): initial guess for center position
        RADIUS_GUESS (int): initial guess for the radius
        DISK_RADIUS (int): value for disk radius used in mapping

    Returns:
        center_x (array): One-dimensional array of x values for the center position of each image
        center_y (array): One-dimensional array of y values for the center position of each image"""

    center_x = []
    center_y = []
    with concurrent.futures.ThreadPoolExecutor() as executor:
        results = executor.map(finding_center_alg, data_array)

    for result in results:
        center_x.append(result[0])
        center_y.append(result[1])

    center_x = np.array(center_x)
    center_y = np.array(center_y)
    if plot == True:
        plt.figure(figsize=(10, 10))
        plt.subplot(2, 1, 1)
        plt.plot(center_x[:])
        plt.title("X values for Centers")
        plt.xlabel("Image Number")
        plt.ylabel("Pixel Value")

        plt.subplot(2, 1, 2)
        plt.plot(center_y[:-3])
        plt.title("Y values for Centers")
        plt.xlabel("Image Number")
        plt.ylabel("Pixel Value")

        plt.show()
    if print_stats == True:
        x_ave = np.mean(center_x[np.where(center_x != CENTER_GUESS[0])[0]])
        y_ave = np.mean(center_y[np.where(center_y != CENTER_GUESS[1])[0]])
        center_x[np.where(center_x == CENTER_GUESS[0])[0]] = x_ave
        center_y[np.where(center_y == CENTER_GUESS[1])[0]] = y_ave
        center_ave = x_ave, y_ave
        print(r'Averaged ctr is ' + str(center_ave))
        fail_count = np.count_nonzero(np.array(center_x) == CENTER_GUESS[0])

        print(
            f"Percentage of images where the center finding failed (i.e., found the guess value): {fail_count / len(data_array) * 100}")
    return center_x, center_y


### Azimuthal Averaging and Radial Outlier Removal Functions

# high standard deviation checking and removing

def get_azi_ave(image, center=None):
    """Takes a single 2d array and converts to polar coordinates based on the supplied center value. Then calculates
    the average and standard deviation at each radial distance. Returns the azimuthal average and standard deviation
    as well as the image in polar coordinates.

    Arguments:
        image (2d array): individual image from the larger data set
        center (list with length 2): center x and center y values #todo fix how it handles the center

    Returns:
        azi_ave (1d array): average values for each radius
        azi_std (1d array): standard deviation for each radius
        polar_image (2d array): original image converted to polar coordinates"""


    if center is None:
        center = (image.shape[1] // 2, image.shape[0] // 2)  # Assuming center is at the middle

    # Create meshgrid of coordinates
    y, x = np.indices(image.shape[:2])

    # Convert coordinates to polar coordinates
    theta = np.arctan2(y - center[1], x - center[0])
    rho = np.sqrt((x - center[0]) ** 2 + (y - center[1]) ** 2)

    # Normalize rho to [0, max_radius] for image indexing
    max_radius = np.sqrt(center[0] ** 2 + center[1] ** 2)
    # max_radius = len(image[0]) - min(center)
    print(max_radius)
    rho_normalized = (rho / max_radius) * (image.shape[0] / 2)

    # Convert theta to degrees and ensure it's within [0, 360]
    theta_degrees = np.degrees(theta) % 360

    # Create polar image with correct dimensions
    polar_image = np.empty((int(max_radius), 360))
    polar_image.fill(np.nan)

    # Fill in the polar image with values from the original image
    for i in range(image.shape[0]):
        for j in range(image.shape[1]):
            polar_image[int(rho_normalized[i, j]), int(theta_degrees[i, j])] = image[i, j]

    azi_ave = np.nanmean(polar_image, axis=1)
    azi_std = np.nanstd(polar_image, axis=1)
    return azi_ave, azi_std, polar_image

def remove_radial_outliers(image, center, plot=False, fill_value = 'nan'):
    """Takes a single 2d image and identifies instances where the pixel value at any radius is an outlier. The bad pixel
    is then replaced with either np.nan or the interpolated average value.

    Arguments:
        image (2d array): single image
        center (list): center x value and center y value *NOTE: if center value is bad, percentage of pixels removed
            will be larger

    Optional Arguments:
        plot (boolean): Default set to False. When true, plots the input image and the cleaned image.
        fill_value (string of either 'nan' or 'ave'): defines whether bad pixels are replaced by np.nan or average

    Returns:
        clean_image (2d array): image with outliers removed
        idx_outliers (list): coordinates for outlier pixels"""
    radial_avgs, radial_stdevs, _ = get_azi_ave(image)
    new_image = np.empty((len(image[0]), len(image[1])))
    new_image.fill(np.nan)
    x_center = center[0]
    y_center = center[1]
    #idx_outliers = np.ones((len(image[0]), len(image[1])))
    idx_outliers = []
    if fill_value == 'nan':
        for x in range(len(image[0])):
            for y in range(len(image[1])):
                R = sqrt((x - x_center) ** 2 + (y - y_center) ** 2)
                # Calculate the interpolated value for the average and stdev at this R
                # (Same thing I do in simulate_image but now I'm calculating the weighted average of the
                # average intensity values so the language is a little confusing)
                interpolated_avg, interpolated_stdev = 0, 0  # Will be filled in with the interpolated values

                R_lower = floor(R)
                R_upper = R_lower + 1
                if R_lower >= len(radial_avgs):
                    interpolated_avg = 0  # R value is out of bounds, default to 0
                    interpolated_stdev = 0
                elif R_upper >= len(radial_avgs):
                    interpolated_avg = radial_avgs[R_lower]  # R value is just outside of bounds, default to edge value
                    interpolated_stdev = radial_stdevs[R_lower]
                else:
                    # Calculate weighted average
                    interpolated_avg = (R - R_lower) * radial_avgs[R_upper] + (R_upper - R) * radial_avgs[R_lower]
                    interpolated_stdev = (R - R_lower) * radial_stdevs[R_upper] + (R_upper - R) * radial_stdevs[R_lower]

                if abs(image[x][y] - interpolated_avg) <= 3 * interpolated_stdev:
                    # Value is within acceptance range, do not change
                    new_image[x][y] = image[x][y]
                else:
                    # Value is outside acceptance range, use average value instead
                    new_image[x][y] = np.nan
                    idx_outliers.append([x, y])

    if fill_value == 'ave':
        for x in range(len(image[0])):
            for y in range(len(image[1])):
                R = sqrt((x - x_center) ** 2 + (y - y_center) ** 2)
                # Calculate the interpolated value for the average and stdev at this R
                # (Same thing I do in simulate_image but now I'm calculating the weighted average of the
                # average intensity values so the language is a little confusing)
                interpolated_avg, interpolated_stdev = 0, 0  # Will be filled in with the interpolated values

                R_lower = floor(R)
                R_upper = R_lower + 1
                if R_lower >= len(radial_avgs):
                    interpolated_avg = 0  # R value is out of bounds, default to 0
                    interpolated_stdev = 0
                elif R_upper >= len(radial_avgs):
                    interpolated_avg = radial_avgs[R_lower]  # R value is just outside of bounds, default to edge value
                    interpolated_stdev = radial_stdevs[R_lower]
                else:
                    # Calculate weighted average
                    interpolated_avg = (R - R_lower) * radial_avgs[R_upper] + (R_upper - R) * radial_avgs[R_lower]
                    interpolated_stdev = (R - R_lower) * radial_stdevs[R_upper] + (R_upper - R) * radial_stdevs[R_lower]

                if abs(image[x][y] - interpolated_avg) <= 3 * interpolated_stdev:
                    # Value is within acceptance range, do not change
                    new_image[x][y] = image[x][y]
                else:
                    # Value is outside acceptance range, use average value instead
                    new_image[x][y] = interpolated_avg
                    idx_outliers.append([x, y])

    pct_outlier = (len(idx_outliers)/(len(image[0])*len(image[1])))*100
    print(f"Percent outliers in image is {pct_outlier:.2f}.")

    if plot == True:
        plt.figure(figsize=(14, 8))
        plt.subplot(1, 2, 1)
        plt.imshow(np.log(image), cmap='bwr')
        plt.colorbar()
        plt.clim(6, 7)
        plt.title('Original Image')

        plt.subplot(1, 2, 2)
        plt.imshow(np.log(new_image), cmap='bwr')
        plt.colorbar()
        plt.clim(6, 7)
        plt.title('New Image')

        plt.show()
    return new_image, idx_outliers



### PDF Generating Functions
# todo add theses functions
