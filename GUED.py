# todo Clean importing calls
# Standard Packages
import numpy as np
import numpy.ma as ma
from tifffile import tifffile as tf
import matplotlib.pyplot as plt
import pandas as pd
import scipy.signal as ss
import concurrent.futures
from functools import partial

# Image stuff
import matplotlib.patches as patches
from skimage.filters import threshold_otsu
from skimage.morphology import closing, square, disk
from skimage.segmentation import clear_border
from skimage.measure import label, regionprops_table
from skimage import util, draw

# Configuration File
from gued_globals import *


### Reading Images Functions

def _show_counts(stage_positions, counts):
    """Function for visualizing and plotting total counts from a set of data. Called within the get_image_details
    function when plot == True"""

    counts_mean = np.mean(counts)  # Mean values of Total Counts of all images
    counts_std = np.std(counts)  # the STD of all the tc for all the iamges
    uni_stage = np.unique(stage_positions)  # Pump-probe stage position
    plt.figure()  # Plot counts rate, images number at each posi, and bad images

    plt.subplot(1, 3, 1)
    plt.plot(counts, '-d')
    plt.axhline(y=counts_mean, color='k', linestyle='-', linewidth=1, label="mean counts");
    plt.axhline(y=counts_mean - (3 * counts_std), color='r', linestyle='-', linewidth=0.5, label="min counts");
    plt.axhline(y=counts_mean + (3 * counts_std), color='r', linestyle='-', linewidth=0.5, label="max counts");
    plt.xlabel('Images orderd in lab time');
    plt.ylabel('Counts');
    plt.legend()
    plt.title('Total counts');

    plt.subplot(1, 3, 2)  # Histogram the number of images at each posi
    plt.plot(uni_stage, '-o');
    plt.xlabel('pp stage posi');
    plt.ylabel('Stg Position [mm]');
    plt.title('Delay Stage Position');

    plt.subplot(1, 3, 3)  # Histogram the number of images at each posi
    posi_edges_bins = np.append(uni_stage - 0.001, uni_stage[-1])
    posi_hist, posi_edges = np.histogram(stage_positions, bins=posi_edges_bins)
    plt.plot(uni_stage, posi_hist, '-*')
    plt.xlabel('pp stage posi [mm]');
    plt.ylabel('Num of Imges');
    plt.title('Num of images at each delay');

    plt.tight_layout()
    plt.show()


def _get_counts(data_array, plot=False):
    """
    Generates the counts from the given data by summing over the array elements. Returns 2d array of the same dimension as the
    input images.

    ARGUMENTS:

    data_array (3d array): 
        Array containing the diffraction images.
    
    OPTIONAL ARGUMENTS:

    plot (boolean): 
        Default set to False. When true, plots a graph of the counts data.

    RETURNS:

    counts (2d array): 
        One dimensional array containing the data after summing over each array element.

    """
    counts = np.sum(data_array, axis=(1, 2))
    if len(data_array) == 0:
        raise ValueError("Input data_array is empty.")
    if data_array.ndim != 3:
        raise ValueError("Input data_array is not 3 dimensional.")
    if plot == True:
        plt.plot(np.arange(len(data_array[:, 0, 0])), counts)
        plt.show()
    return counts


def get_image_details(file_names, sort=True, plot=False,
                      filter_data=False):  # looks pretty good for now todo look into optional arguments
    """
    Reads all images from input file_names and returns the data as a 3d array along with stage positions, order, and counts per image.

    ARGUMENTS:

    file_names (list):
        list of file names to be read in

    OPTIONAL ARGUMENTS:

    sort (boolean): 
        default is set to True. This arguments sorts the data based on when it was saved (i.e. file number)
    plot (boolean): 
        default is set to False. When True, a plot of the data, log(data), and histogram of counts is shown
    filter_data (boolean): 
        default is set to False. When True, code prompts you for a minimum and maximum value then
        returns only the information from files within this range

    RETURNS:

    data_array (3d array): 
        Array of N x 1024 x 1024 where N is the length of tile file_names list. Generated by using tifffile as tf.
    stage_positions (array): 
        An array containing the stage positions of the file. The index of each stage position corresponds to the index of the file name 
        in file_names.
    file_order (array): 
        Returns the image number located in the file name. Reflects the order with which the images are taken.
    counts(array): 
        One dimensional numpy array of length N containing the data after summing over each array element.

    """
    data_array = tf.imread(file_names)  # construct array containing files

    try:
        stage_pos = []
        file_order = []
        try:
            # stage_pos = [np.float64(file_name[idx_start:idx_end]) for file_name in file_names]
            # stage_pos = np.array(stage_pos)
            for file in file_names:
                string = list(
                    map(str, file.split("\\")))  # Note standard slash usage for windows todo might need to test
                folder_number = string[-3][-3:]
                string = list(map(str, string[-1].split("-")))
                file_number = int(folder_number + string[1])
                file_order.append(int(file_number))
                string = list(map(str, string[-1].split("_")))
                stage_pos.append(float(string[0]))
        except ValueError:
            raise ValueError("""Failed to convert a file name to a float. Make sure that index positions are correct for all files in file_names. 
            Also check separators""")
    except IndexError:
        raise ValueError(
            "Invalid index values. Make sure the index values are within the range of the file name strings.")

    stage_pos = np.array(stage_pos)
    file_order = np.array(file_order)
    counts = _get_counts(data_array)

    if sort == True:
        idx_sort = np.argsort(file_order)
        file_order = file_order[idx_sort]
        data_array = data_array[idx_sort]
        stage_pos = stage_pos[idx_sort]
        counts = counts[idx_sort]

    if filter_data == True:
        min_val = int(input("Enter minimum file number: "))
        max_val = int(input("Enter maximum file number: "))
        try:
            good_range = np.arange(min_val, max_val, 1)
            data_array = data_array[good_range]
            stage_pos = stage_pos[good_range]
            counts = counts[good_range]
            file_order = file_order[good_range]
        except:
            print("Max value is larger than the size of the data range, returning all data")

    if plot == True:
        test = data_array[0]
        plt.figure(figsize=[12, 10])
        plt.subplot(1, 3, 1);
        plt.imshow(test, cmap='jet');
        plt.xlabel('Pixel');
        plt.ylabel('Pixel');
        plt.title('Linear Scale(data)')

        plt.subplot(1, 3, 2);
        plt.imshow(np.log(test), cmap='jet');
        plt.xlabel('Pixel');
        plt.ylabel('Pixel');
        plt.title('Log Scale(data)')

        plt.subplot(1, 3, 3);
        plt.hist(test.reshape(-1), bins=30, edgecolor="r", histtype="bar", alpha=0.5)
        plt.xlabel('Pixel Intensity');
        plt.ylabel('Pixel Number');
        plt.title('Hist of the pixel intensity(data)');
        plt.yscale('log')
        plt.tight_layout()
        plt.show()

        _show_counts(stage_pos, counts)

    return data_array, stage_pos, file_order, counts


def get_image_details_slac(file_names, sort=True):  # todo update to look like others
    """
    Reads all images from input file_names and returns the data as a 3d array along with stage positions, order, and counts per image.

    ARGUMENTS:

    file_names (list):
        list of file names to be read in

    OPTIONAL ARGUMENTS:

    sort (boolean): 
        default is set to True. This arguments sorts the data based on when it was saved (i.e. file number)
    plot (boolean): 
        default is set to False. When True, a plot of the data, log(data), and histogram of counts is shown
    filter_data (boolean): 
        default is set to False. When True, code prompts you for a minimum and maximum value then
        returns only the information from files within this range

    RETURNS:

    data_array (3d array): 
        Array of N x 1024 x 1024 where N is the length of tile file_names list. Generated by using tifffile as tf.
    stage_positions (array): 
        An array containing the stage positions of the file. The index of each stage position corresponds to the index of the file name 
        in file_names.
    file_order (array): 
        Returns the image number located in the file name. Reflects the order with which the images are taken.
    counts(array): 
        One dimensional numpy array of length N containing the data after summing over each array element.

    """
    data_array = tf.imread(file_names)  # construct array containing files

    try:
        stage_pos = []
        file_order = []
        try:
            # stage_pos = [np.float64(file_name[idx_start:idx_end]) for file_name in file_names]
            # stage_pos = np.array(stage_pos)
            for file in file_names:
                string = list(map(str, file.split("/")))
                string = list(map(str, string[-1].split("_")))
                file_order.append(int(string[2]))
                stage_pos.append(float(string[3]))
        except ValueError:
            raise ValueError(
                """Failed to convert a file name to a float. Make sure that index positions are correct for all files in file_names. Also check separators""")
    except IndexError:
        raise ValueError(
            "Invalid index values. Make sure the index values are within the range of the file name strings.")

    stage_pos = np.array(stage_pos)
    file_order = np.array(file_order)
    counts = _get_counts(data_array)

    if sort == True:
        idx_sort = np.argsort(file_order)
        file_order = file_order[idx_sort]
        data_array = data_array[idx_sort]
        stage_pos = stage_pos[idx_sort]
        counts = counts[idx_sort]

    return data_array, stage_pos, file_order, counts


def get_image_details_keV(file_names, sort=False, multistage=False):
    # todo update to look like other get_image_details code and make for one stage
    """
    Reads all images from input file_names and returns the data as a 3d array along with stage positions, order, and counts per image.

    ARGUMENTS:

    file_names (list):
        list of file names to be read in

    OPTIONAL ARGUMENTS:

    sort (boolean): 
        default is set to True. This arguments sorts the data based on when it was saved (i.e. file number)
    plot (boolean): 
        default is set to False. When True, a plot of the data, log(data), and histogram of counts is shown
    filter_data (boolean): 
        default is set to False. When True, code prompts you for a minimum and maximum value then
        returns only the information from files within this range

    RETURNS:

    data_array (3d array): 
        Array of N x 1024 x 1024 where N is the length of tile file_names list. Generated by using tifffile as tf.
    stage_positions (array): 
        An array containing the stage positions of the file. The index of each stage position corresponds to the index of the file name 
        in file_names.
    file_order (array): 
        Returns the image number located in the file name. Reflects the order with which the images are taken.
    counts(array): 
        One dimensional numpy array of length N containing the data after summing over each array element.

    """
    data_array = tf.imread(file_names)  # construct array containing files
    if multistage == True:
        try:
            ir_stage_pos = []
            uv_stage_pos = []
            file_order = []
            current = []
            try:
                for file in file_names:
                    string = list(map(str, file.split("/")))
                    string = list(map(str, string[-1].split("_")))
                    file_number = int(string[1])
                    file_order.append(file_number)
                    ir_stage_pos.append(float(string[4]))
                    uv_stage_pos.append(float(string[6]))
                    current.append(float(string[-1][:-5]))
            except ValueError:
                raise ValueError("""Failed to convert a file name to a float. Make sure that index positions are correct for all files in file_names. 
                Also check separators""")
        except IndexError:
            raise ValueError(
                "Invalid index values. Make sure the index values are within the range of the file name strings.")

        ir_stage_pos = np.array(ir_stage_pos)
        uv_stage_pos = np.array(uv_stage_pos)
        file_order = np.array(file_order)
        current = np.array(current)
        counts = _get_counts(data_array)

        if sort == True:
            temp_idx = _sort_files_multistage(file_order, ir_stage_pos, uv_stage_pos)
            data_array = data_array[temp_idx]
            ir_stage_pos = ir_stage_pos[temp_idx]
            uv_stage_pos = uv_stage_pos[temp_idx]
            file_order = file_order[temp_idx]
            current = current[temp_idx]
            counts = counts[temp_idx]
        return data_array, ir_stage_pos, uv_stage_pos, file_order, counts, current

    if multistage == False:
        try:
            stage_positions = []
            file_order = []
            current = []
            try:
                for file in file_names:
                    string = list(map(str, file.split("/")))
                    string = list(map(str, string[-1].split("_")))
                    file_number = int(string[1])
                    file_order.append(file_number)
                    stage_positions.append(float(string[4]))
                    current.append(float(string[-1][:-5]))
            except ValueError:
                raise ValueError("""Failed to convert a file name to a float. Make sure that index positions are correct for all files in file_names. 
                Also check separators""")
        except IndexError:
            raise ValueError(
                "Invalid index values. Make sure the index values are within the range of the file name strings.")

        stage_positions = np.array(stage_positions)
        file_order = np.array(file_order)
        current = np.array(current)
        counts = _get_counts(data_array)

        if sort == True:
            temp_idx = _sort_files(file_order, stage_positions)
            data_array = data_array[temp_idx]
            stage_positions = stage_positions[temp_idx]
            file_order = file_order[temp_idx]
            current = current[temp_idx]
            counts = counts[temp_idx]

    return data_array, stage_positions, file_order, counts, current


def _sort_files_multistage(file_order, ir_stage_pos, uv_stage_pos):
    """ Hidden function for sorting files for experiments with multiple stage positions"""
    uni_stage_ir = np.unique(ir_stage_pos)  # Pump-probe stage position
    uni_stage_uv = np.unique(uv_stage_pos)

    if len(uni_stage_ir) > 1:
        stage_positions = ir_stage_pos
        print("sorting based on IR stage position")
    elif len(uni_stage_uv) > 1:
        stage_positions = uv_stage_pos
        print("sorting based on UV stage position")
    else:
        print("Bad Stage Positions")
    idx_list = []
    uni_stage = np.unique(stage_positions)
    for i in range(len(uni_stage)):
        # file_numbers = file_order[np.where(stage_positions==uni_stage[i])[0]];
        # file_numbers = file_numbers[idx_temp]
        stage_idx = np.where(stage_positions == uni_stage[i])[0]
        file_numbers = file_order[stage_idx]
        idx_temp = np.argsort(file_numbers)
        # print(file_numbers[idx_temp])
        idx_list.append(stage_idx[idx_temp])
    idx_list = np.array(idx_list)
    idx_list = np.reshape(idx_list, len(stage_positions))
    return idx_list


def _sort_files(file_order, stage_positions):
    """Hidden function for sorting files based on image name"""
    uni_stage = np.unique(stage_positions)  # Pump-probe stage position

    idx_list = []

    for i in range(len(uni_stage)):
        # file_numbers = file_order[np.where(stage_positions==uni_stage[i])[0]];
        # file_numbers = file_numbers[idx_temp]
        stage_idx = np.where(stage_positions == uni_stage[i])[0]
        file_numbers = file_order[stage_idx]
        idx_temp = np.argsort(file_numbers)
        # print(file_numbers[idx_temp])
        idx_list.append(stage_idx[idx_temp])
    idx_list = np.array(idx_list)
    idx_list = np.reshape(idx_list, len(stage_positions))
    return idx_list


### Cleaning Functions 

def remove_counts(data_array, stage_positions, file_order, counts, std_factor=3, plot=False):
    # todo add edge option
    """
    Filters input parameters by removing any data where the total counts falls outside of the set filter. Default
    value is set to 3 standard deviations from the mean. Returns the same variables as it inputs but with
    different dimensions.

    ARGUMENTS:

    data_array (ndarray): 
        Multidimensional array of N x 1024 x 1024 where N is the length of file_names list
    stage_pos (array): 
        One dimensional array of length N containing the stage positions associated with each image.
    file_order (array): 
        One dimensional array of length N that reflects the order with which the images are taken.
    counts(ndarray): 
        One dimensional array of length N containing the total counts after summing over each array
        element.

    OPTIONAL ARGUMENTS:

    std_factor (int): 
        Default value is 3. Refers to cut off based on number of standard deviations from the mean.
    plot (boolean): 
        Default is False. Returns a plot of new and old counts.

    RETURNS:

    Returns same variables which it received as arguments with new N value.

    """

    init_length = len(counts)
    # Decide to use threshold or selected images
    counts_mean = np.mean(counts)  # Mean values of Total Counts of all images
    counts_std = np.std(counts)  # the STD of all the tc for all the iamges

    tc_good = np.squeeze(
        np.where(abs(counts - counts_mean) < std_factor * counts_std))  # Find out the indices of the low counts images
    new_array = data_array[tc_good]
    new_stage_positions = stage_positions[tc_good]
    new_counts = counts[tc_good]
    new_file_order = file_order[tc_good]

    print(init_length - len(tc_good), " number of files removed from ", init_length, " initial files")

    if plot == True:
        plt.figure(figsize=(12, 4))  # Plot counts rate, images number at each posi, and bad images

        plt.plot(new_counts, '-d')
        plt.axhline(y=counts_mean, color='k', linestyle='-', linewidth=1, label="mean counts");
        plt.axhline(y=counts_mean - (3 * counts_std), color='r', linestyle='-', linewidth=0.5, label="min counts");
        plt.axhline(y=counts_mean + (3 * counts_std), color='r', linestyle='-', linewidth=0.5, label="max counts");
        plt.xlabel('Images orderd in lab time');
        plt.ylabel('Counts');
        plt.legend()
        plt.title('Total counts');

        plt.tight_layout()
        plt.show()

    return new_array, new_stage_positions, new_file_order, new_counts


def remove_background(data_array, remove_noise=True, plot=False, print_status=True):  # todo parallelize
    """
    Takes in a 3d data array and calculates the means of the corners then linearly interpolates values based on corners across 3d array to 
    generate of background noise values using pandas.DataFrame.interpolate.

    ARGUMENTS:

    data_array (3d ndarray): 
        array containing all data

    OPTIONAL ARGUMENTS:

    remove_noise (boolean): 
        Default set to true, returns image with background subtracted. If false, returns
        interpolated background.
    plot (boolean): 
        Default set to False. Plots images showing the original image, interpolated background, and
        background subtracted image.
    print_status (boolean): 
        Default set to True. Prints a status update every nth image (n defined via CHECK_NUMBER).

    GLOBAL VARIABLES:

    CORNER_RADIUS (int): 
        defines the size of the corners being used in background suptraction.
    CHECK_NUMBER (int): 
        defines how often updates are given when print_status == True

    RETURNS:

    clean_data (3d ndarray): 
        Returns array of images with background subtracted if remove_noise == True, else returns
        array of interpolated background.

    """

    if not isinstance(data_array, np.ndarray):
        raise ValueError("Input data_array must be a numpy array.")
    if not isinstance(CORNER_RADIUS, int) and CORNER_RADIUS > 0:
        raise ValueError("bkg_range must be an integer > 0.")
    if not isinstance(remove_noise, bool):
        raise ValueError("remove_noise must be a boolean.")
    if not (2 * CORNER_RADIUS < len(data_array[:, 0, :]) and
            2 * CORNER_RADIUS < len(data_array[:, :, 0])):
        raise ValueError("2 * bkg-range must be less than both the number of rows and the number of columns.")

    clean_data = []
    bkg_data = []
    for i, image in enumerate(data_array):
        empty_array = np.empty(np.shape(image))
        empty_array = (ma.masked_array(empty_array, mask=True))
        empty_array[0, 0] = np.mean(image[0:CORNER_RADIUS, 0:CORNER_RADIUS])
        empty_array[-1, 0] = np.mean(image[-CORNER_RADIUS:, 0:CORNER_RADIUS])
        empty_array[0, -1] = np.mean(image[0:CORNER_RADIUS, -CORNER_RADIUS:])
        empty_array[-1, -1] = np.mean(image[-CORNER_RADIUS:, -CORNER_RADIUS:])
        empty_array = pd.DataFrame(empty_array).interpolate(axis=0)
        empty_array = pd.DataFrame(empty_array).interpolate(axis=1)
        bkg = pd.DataFrame.to_numpy(empty_array)
        bkg_data.append(bkg)
        clean_data.append(image - bkg)
        if print_status == True:
            if i % CHECK_NUMBER == 0:
                print(f"Subtracting background of {i}th image.")

    if plot == True:
        plt.figure()

        plt.subplot(1, 3, 1)
        plt.imshow(data_array[0])
        plt.title("Original Data")

        plt.subplot(1, 3, 2)
        plt.imshow(bkg_data[0])
        plt.title("Interpolated Background")

        plt.subplot(1, 3, 3)
        plt.imshow(clean_data[0])
        plt.title("Background Free Data")
        plt.tight_layout()
        plt.show()

    if remove_noise == True:
        return np.array(clean_data)
    else:
        return np.array(bkg_data)


def _remove_background(image):
    """
    Takes in a 2d data array (using the mean array is recommended) and calculates the means of the corners. Linearly
    interpolates values across 2d array to generate of background noise values using pandas.DataFrame.interpolate.

    ARGUMENTS:

    image (2d ndarray): 
        single image array

    GLOBAL VARIABLES:

    CORNER_RADIUS (int): 
        defines the size of the corners being used in background suptraction.
    CHECK_NUMBER (int): 
        defines how often updates are given when print_status == True

    RETURNS:

    clean_image (2d ndarray): 
        Returns image with background subtracted if remove_noise == True, else returns array of interpolated background.

    """
    if not isinstance(image, np.ndarray):
        raise ValueError("Input data_array must be a numpy array.")
    if not isinstance(CORNER_RADIUS, int) and CORNER_RADIUS > 0:
        raise ValueError("bkg_range must be an integer > 0.")
    if not (2 * CORNER_RADIUS < len(image[0, :]) and
            2 * CORNER_RADIUS < len(image[:, 0])):
        raise ValueError("2 * bkg-range must be less than both the number of rows and the number of columns.")

    clean_data = []
    bkg_data = []

    empty_array = np.empty(np.shape(image))
    empty_array = (ma.masked_array(empty_array, mask=True))
    empty_array[0, 0] = np.mean(image[0:CORNER_RADIUS, 0:CORNER_RADIUS])
    empty_array[-1, 0] = np.mean(image[-CORNER_RADIUS:, 0:CORNER_RADIUS])
    empty_array[0, -1] = np.mean(image[0:CORNER_RADIUS, -CORNER_RADIUS:])
    empty_array[-1, -1] = np.mean(image[-CORNER_RADIUS:, -CORNER_RADIUS:])
    empty_array = pd.DataFrame(empty_array).interpolate(axis=0)
    empty_array = pd.DataFrame(empty_array).interpolate(axis=1)
    bkg = pd.DataFrame.to_numpy(empty_array)
    bkg_data.append(bkg)
    clean_data.append(image - bkg)

    return np.squeeze(np.array(clean_data)), np.squeeze(np.array(bkg_data))

def remove_background_pool(data_array, remove_noise=True, plot=False):
    """ 
    Removes the background of images based on the corners. Runs the hidden function _remove_background and runs it in parallel.

    ARGUMENTS:

    data_array (3d array): 
        data array of all images

    OPTIONAL ARGUMENTS:

    remove_noise (boolean): 
        Default set to true. Returns data array with noise removed. If false, only returns the interpolated background
    plot (boolean): 
        Default set to false. When true, plots an example of original data, interpolated background, and cleaned image.

    RETURNS:

    clean_data (3d array): 
        Original data with background removed when remove_noise==True
    or
    backgrounds (3d array):
        Interpolated background for each image when remove_noise==False

    """
    clean_data = []
    backgrounds = []
    with concurrent.futures.ProcessPoolExecutor() as executor:
        results = executor.map(_remove_background, data_array)

    for result in results:
        clean, bkg = result
        clean_data.append(clean)
        backgrounds.append(bkg)

    clean_data = np.array(clean_data)
    backgrounds = np.array(backgrounds)

    if plot == True:
        plt.figure()

        plt.subplot(1, 3, 1)
        plt.imshow(data_array[0])
        plt.title("Original Data")

        plt.subplot(1, 3, 2)
        plt.imshow(backgrounds[0])
        plt.title("Interpolated Background")

        plt.subplot(1, 3, 3)
        plt.imshow(clean_data[0])
        plt.title("Background Free Data")
        plt.tight_layout()
        plt.show()

    if remove_noise == True:
        return clean_data
    else:
        return backgrounds


def remove_xrays_pool(data_array, plot=True, std_factor=3):
    """
    Filters out any pixels that are more than set threshold value based on the standard deviation of the
    average pixel value by running the hidden function _remove_xrays in parallel.

    ARGUMENTS:

    data_array (3d array): 
        array of image like data with length N where N is number of images.

    OPTIONAL ARGUMENTS:

    plot (boolean): 
        Default set to True. Plots the percentage of pixeled removed during cleaning process
    std_factor (int): 
        Default set to 3. Defines the threshold for removing pixels with |pixel_value - mean| > std_factor*std

    RETURNS:

    clean_data (3d array): 
        array of image like data with shape of input data array where errant pixels are now masked based on the set threshold

    """

    mean_data = np.mean(data_array, axis=0)
    std_data = np.std(data_array, axis=0)
    print("Removing hot pixels from all data")
    with concurrent.futures.ThreadPoolExecutor() as executor:
        futures = [executor.submit(partial(_remove_xrays, mean_data, std_data, std_factor), data) for
                   data in data_array]
        results = [future.result() for future in futures]

    clean_data = []
    amt_rmv = []
    for result in results:
        data, amt = result
        clean_data.append(data)
        amt_rmv.append(amt)

    pct_rmv = np.array(amt_rmv) / (len(data_array[1]) * len(data_array[2])) * 100

    if plot == True:
        plt.figure()
        plt.subplot(1, 3, 1)
        plt.plot(pct_rmv)
        plt.title("Percent Pixels Removed")
        plt.xlabel("Image Number")
        plt.ylabel("Percent")

        plt.subplot(1, 3, 2)
        plt.imshow(data_array[0])
        plt.title("Original Image")

        plt.subplot(1, 3, 3)
        plt.imshow(clean_data[0])
        plt.title("Cleaned Image")
        plt.tight_layout()
        plt.show()

    return clean_data


def _remove_xrays(data_array_1d, mean_data, std_data, std_factor=3):
    """This is the hidden function that is run within the remove_xrays_pool function.

    ARGUMENTS:

    data_array (2d array): 
        array of image like data with length N where N is number of images.
    mean_data (2d array): 
        average image of all data in data_array from parent function.
    std_data (2d array): 
        image with standard deviation values from all data in data_array in parent function.

    OPTIONAL ARGUMENTS:

    std_factor (int): 
        Default set to 3. Defines the threshold for removing pixels with |pixel_value - mean| > std_factor*std

    RETURNS:

    clean_data (2d array): 
        array of image like data with shape of input data array where errant pixels are now masked based on the set threshold
        amt_rmv (int): count of all pixels removed per image

    """

    upper_threshold = mean_data + std_factor * std_data
    clean_data = ma.masked_greater_equal(data_array_1d, upper_threshold)
    amt_rmv = np.sum(clean_data.mask)
    return clean_data, amt_rmv


def remove_xrays(data_array): # testing for timing

    mean_data = np.nanmean(data_array, axis=0)
    std_data = np.nanstd(data_array, axis=0)
    clean_data = []
    for i in range(len(data_array)):
        temp, _ = _remove_xrays(data_array[0], mean_data, std_data)
        clean_data.append(temp)
    
    clean_data = np.array(clean_data)
    return clean_data


def subtract_background(data_array, mean_background, plot=True):
    """Takes in 3d data_array and subtracts each image from the input mean_background 2d array. Returns cleaned
    data_array

    ARGUMENTS:

    data_array (3d array): 
        original data array
    mean_background (2d array): 
        average of background images

    OPTIONAL ARGUMENTS:

    plot (boolean): 
        Default is True. Plots example original image and background subtracted image

    RETURNS:

    clean_data (3d array): 
        data_array - mean_background
    """

    clean_data = data_array - mean_background

    if plot == True:
        plt.figure()
        plt.subplot(1, 2, 1)
        plt.imshow(data_array[0])
        plt.title("Original Image")

        plt.subplot(1, 2, 2)
        plt.imshow(clean_data[0])
        plt.title("Cleaned Image")
        plt.tight_layout()
        plt.show()

    return clean_data


# Masking and Center Finding Functions

def mask_generator_alg(image, mask_center, mask_radius, fill_value=np.nan, add_mask=[], add_rectangular=False):
    """
    Generate mask to cover unwanted area

    ARGUMENTS:

    image : 2D array
        Diffraction pattern.
    mask_center : 1D array, tuple, or list that contains only two values
        Center for generating mask cover unscattered electron beam.
    mask_radius : int
        Radius of the mask.
    fill_value : int, float, or nan, optional
        Value that use to fill the area of the mask. The default is np.nan.
    add_mask : list of 3-value-lists, optional
        Additional masks. Input gonna be [[x-center, y-center, radius], [...], ...] The default is [].
    add_rectangular : boolean, optional
        Additional mask with rectangular shape. The default is True.
    showingfigure : boolean, optional
        Show figure of the result of applied masks. The default is False.

    RETURNS:
    
    mask : binary 2D array
        Result of all the masks in an image.

    """

    mask = np.ones(image.shape)
    rows, cols = draw.disk((mask_center[1], mask_center[0]), mask_radius, shape=mask.shape)
    mask[rows, cols] = fill_value

    if len(add_mask) == 0:
        pass
    else:
        for i in add_mask:
            rows, cols = draw.disk((i[1], i[0]), i[2], shape=mask.shape)
            mask[rows, cols] = fill_value

    # retangular mask
    if add_rectangular == True:
        rr, cc = draw.rectangle((0, 590), extent=(500, 40), shape=image.shape)  # (0,535) for iodobenzene
        mask[rr, cc] = fill_value
        # 515

    return mask


def apply_mask(data_array, mask_center, mask_radius, fill_value=np.nan, add_mask=[], add_rectangular=False,
               plot=False):  # todo change mask parameters to global variables
    """ Applies a mask to individual images in the data array.

    ARGUMENTS:

    data_array_1d : 2D array
        Diffraction pattern.
    mask_center : 1D array, tuple, or list that contains only two values
        Center for generating mask cover unscattered electron beam.
    mask_radius : int
        Radius of the mask.

    OPTIONAL ARUGMENTS:

    fill_value : int, float, or nan, optional
        Value that use to fill the area of the mask. The default is np.nan.
    add_mask : list of 3-value-lists, optional
        Additional masks. Input gonna be [[x-center, y-center, radius], [...], ...] The default is [].
    add_rectangular : boolean, optional
        Additional mask with rectangular shape. The default is True.
    showingfigure : boolean, optional
        Show figure of the result of applied masks. The default is False.

    RETURNS:

    mask : binary 2D array
        Result of all the masks in an image.

    """
    mean_data = np.nanmean(data_array, axis=0)
    masked_data = data_array * mask_generator_alg(mean_data, mask_center, mask_radius, fill_value, add_mask,
                                                  add_rectangular)
    masked_mean = np.nanmean(masked_data, axis=0)

    print(masked_data.shape)
    if plot == True:
        fig, axs = plt.subplots(1, 3, figsize=(15, 5))

        # First subplot: Mean of Unmasked Data Array
        axs[0].imshow(mean_data)
        axs[0].set_title("Mean of Unmasked Data Array")
        cbar = plt.colorbar(axs[0].imshow(mean_data), ax=axs[0])
        cbar.ax.set_ylabel('Intensity')

        # Second subplot: Mean of Masked Data Array
        axs[1].imshow(masked_mean)
        axs[1].set_title("Mean of Masked Data Array")
        cbar = plt.colorbar(axs[1].imshow(masked_mean), ax=axs[1])
        cbar.ax.set_ylabel('Intensity')

        # Third subplot: Contour map of average data
        x = np.arange(300, 700)
        y = np.arange(300, 700)
        X, Y = np.meshgrid(y, x)
        pc = axs[2].pcolormesh(x, y, np.log(masked_mean[300:700, 300:700]), shading='auto')
        cs = axs[2].contour(X, Y, np.log(masked_mean[300:700, 300:700]), levels=20, colors='w')
        axs[2].set_title('Contour map of average data')
        cbar = fig.colorbar(pc, ax=axs[2])
        cbar.ax.set_ylabel('Log(Intensity)')

        # Adjust layout to prevent overlap
        plt.tight_layout()

        # Show the combined figure
        plt.show()

    return masked_data


def finding_center_alg(data_array, plot=False, title='Reference Image', thresh_input=0):
    """
    Algorithm for finding the center of diffraction pattern

    ARGUMENTS:
    
    data_array : 2D array
        Diffraction pattern.
    DISK_RADIUS : int, optional
        Generates a flat, disk-shaped footprint. The default is 3.
    plot : boolean, optional
        Show figure of the result of center finding. The default is False.
    CENTER_GUESS : tuple contains 2 values, optional
        Guessing center position to generate temporary mask. The default is (532, 520).
    RADIUS_GUESS : int, optional
        Guessing radius of the temporary mask. The default is 80.
    title : str, optional
        Title of the figure. The default is 'Reference image'.

    RETURNS
    
    center_x : int
        Center value on x axis.
    center_y : int
        Center value of y axis.
    radius : int
        Radius of ring used for finding center.

    """

    if thresh_input == 0:
        thresh = threshold_otsu(data_array)
    else:
        thresh = thresh_input

    cxt, cyt = [], []
    for th in [1]:
        thresh *= th
        mask_temp = mask_generator_alg(data_array, CENTER_GUESS, RADIUS_GUESS * th, fill_value=False, add_mask=[],
                                       add_rectangular=False)
        mask_temp = util.invert(mask_temp.astype(bool))
        bw = closing(data_array > thresh, disk(
            DISK_RADIUS))  # Return grayscale morphological closing of an image. Square(): generate the footprint to close the gap between data points
        cleared = clear_border(bw + mask_temp)
        label_image = label(cleared)
        props = regionprops_table(label_image, properties=('centroid',
                                                           'axis_major_length',
                                                           'axis_minor_length'))
        dia = np.array([props['axis_major_length'], props['axis_minor_length']])
        dia = np.mean(dia, axis=0)
        radius = np.amax(dia) / 2
        idx = np.where(dia == np.amax(dia))[0][0]
        cxt.append(props['centroid-1'][idx])
        cyt.append(props['centroid-0'][idx])

    center_x = np.mean(cxt)
    center_y = np.mean(cyt)

    if plot == True:
        fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(20, 10))
        ax1.imshow(data_array)
        ax2.imshow(label_image)
        ax3.imshow(bw)

        for cc in range(len(cxt)):
            circ = patches.Circle((cxt[cc], cyt[cc]), radius, linewidth=1, edgecolor="r", facecolor="none",
                                  linestyle='--')
            ax1.add_patch(circ)
            circ = patches.Circle((cxt[cc], cyt[cc]), radius, linewidth=2, edgecolor="r", facecolor="none")
            ax2.add_patch(circ)
            circ = patches.Circle((cxt[cc], cyt[cc]), radius, linewidth=2, edgecolor="r", facecolor="none")
            ax3.add_patch(circ)

        for ax in (ax1, ax2, ax3):
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)
        ax1.set_title(title, fontsize=20)
        ax2.set_title("Center [X = " + str(center_x) + ", Y = " + str(center_y) + "]", fontsize=20)
        ax3.set_title("Binary image", fontsize=20)

        ax1.axvline(center_x, linestyle='--', lw=1, color='tab:red')
        ax1.axhline(center_y, linestyle='--', lw=1, color='tab:red')

        ax2.axvline(center_x, linestyle='--', lw=2, color='tab:red')
        ax2.axhline(center_y, linestyle='--', lw=2, color='tab:red')

        plt.tight_layout()
        plt.show()

    return center_x, center_y, radius, thresh


def find_center_pool(data_array, plot=True, print_stats=True):
    """ Finds center of each image in the data array using concurrent.futures.ThreadPoolExecutor to quickly process
    many data files.

    ARGUMENTS:

    data_array (ndarray): 
        array of image like data with shape Nx1024x1024

    OPTIONAL ARGUMENTS:

    plot (boolean): 
        Default is set to True. When true, plots an image of the values for center_x and center_y with respect to pixel number
    print_stats (boolean): 
        Default is set to True. Prints the average value for center_x and center_y and prints the percent failure rate.

    GLOBAL VARIABLES:

    CENTER_GUESS (tuple): 
        initial guess for center position
    RADIUS_GUESS (int): 
        initial guess for the radius
    DISK_RADIUS (int): 
        value for disk radius used in mapping

    RETURNS:

    center_x (array):
        One-dimensional array of x values for the center position of each image
    center_y (array): 
        One-dimensional array of y values for the center position of each image"""

    center_x = []
    center_y = []
    with concurrent.futures.ThreadPoolExecutor() as executor:
        results = executor.map(finding_center_alg, data_array)

    for result in results:
        cx, cy, _, _ = result
        center_x.append(cx)
        center_y.append(cy)

    center_x = np.array(center_x)
    center_y = np.array(center_y)
    if plot == True:
        plt.figure(figsize=(10, 10))
        plt.subplot(2, 1, 1)
        plt.plot(center_x[:])
        plt.title("X values for Centers")
        plt.xlabel("Image Number")
        plt.ylabel("Pixel Value")

        plt.subplot(2, 1, 2)
        plt.plot(center_y[:-3])
        plt.title("Y values for Centers")
        plt.xlabel("Image Number")
        plt.ylabel("Pixel Value")

        plt.show()
    if print_stats == True:
        x_ave = np.mean(center_x[np.where(center_x != CENTER_GUESS[0])[0]])
        y_ave = np.mean(center_y[np.where(center_y != CENTER_GUESS[1])[0]])
        center_x[np.where(center_x == CENTER_GUESS[0])[0]] = x_ave
        center_y[np.where(center_y == CENTER_GUESS[1])[0]] = y_ave
        center_ave = x_ave, y_ave
        print(r'Averaged ctr is ' + str(center_ave))
        fail_count = np.count_nonzero(np.array(center_x) == CENTER_GUESS[0])

        print(
            f"Percentage of images where the center finding failed (i.e., found the guess value): {fail_count / len(data_array) * 100}")
    return center_x, center_y


### Azimuthal Averaging and Radial Outlier Removal Functions
def _preprocess_radial_data(image, center=None, plot=False):
    """
    Takes a single 2d array and converts to polar coordinates based on the supplied center value. Then calculates
    the average and standard deviation at each radial distance. Returns the azimuthal average and standard deviation
    as well as the image in polar coordinates.

    ARUGMENTS:

    image (2d array): 
        individual image from the larger data set
    center (list with length 2): 
        center x and center y values #todo fix how it handles the center

    RETURNS:

    azi_ave (1d array): 
        average values for each radius
    azi_std (1d array): 
        standard deviation for each radius
    polar_image (2d array): 
        original image converted to polar coordinates

        """

    from scipy.interpolate import griddata

    # Create meshgrid of coordinates
    x, y = np.indices(image.shape[:2])

    # Convert coordinates to polar coordinates
    theta = np.arctan2(y - center[1], x - center[0])
    rho = np.sqrt((x - center[0]) ** 2 + (y - center[1]) ** 2)

    # Normalize rho to [0, max_radius] for image indexing
    max_radius = np.sqrt(center[0] ** 2 + center[1] ** 2)
    # max_radius = len(image[0]) - min(center)

    rho_normalized = (rho / max_radius) * (image.shape[0] / 2)

    # Convert theta to degrees and ensure it's within [0, 360]
    theta_degrees = np.degrees(theta) % 360

    # Create polar image with correct dimensions
    polar_image = np.empty((int(max_radius), 360))
    polar_image.fill(np.nan)

    # Fill in the polar image with values from the original image
    for i in range(image.shape[0]):
        for j in range(image.shape[1]):
            polar_image[int(rho_normalized[i, j]), int(theta_degrees[i, j])] = image[i, j]

    azi_ave = np.nanmean(polar_image, axis=1)
    azi_std = np.nanstd(polar_image, axis=1)

    # Create the Cartesian coordinate grid
    dimension = len(image)
    radius = np.arange(0, len(azi_ave))
    x = np.arange(dimension) - center[0]
    y = np.arange(dimension) - center[1]
    X, Y = np.meshgrid(x, y)

    # Convert Cartesian coordinates to polar coordinates
    R = np.sqrt(X ** 2 + Y ** 2)
    Theta = np.arctan2(Y, X)

    # Normalize R to match the radius array
    # Define the full polar grid
    theta_full = np.linspace(-np.pi, np.pi, dimension)
    radius_full, theta_full = np.meshgrid(radius, theta_full)

    # Flatten the polar grid arrays for interpolation
    radius_flat = radius_full.flatten()
    theta_flat = theta_full.flatten()

    # Expand polar data to match the full grid shape
    polar_data_ave = np.tile(azi_ave, (theta_full.shape[0], 1)).flatten()
    polar_data_std = np.tile(azi_std, (theta_full.shape[0], 1)).flatten()

    # Interpolate the polar data to the Cartesian grid
    remapped_data = griddata((radius_flat, theta_flat), polar_data_ave,
                             (R.flatten(), Theta.flatten()), method='linear')
    remapped_std = griddata((radius_flat, theta_flat), polar_data_std,
                            (R.flatten(), Theta.flatten()), method='linear')

    # Reshape the interpolated data to the Cartesian grid dimensions
    remapped_data = remapped_data.reshape(dimension, dimension)
    remapped_std = remapped_std.reshape(dimension, dimension)

    # Plot the Cartesian image
    if plot == True:
        plt.imshow(remapped_data, origin='lower', extent=(-center[0], center[0], -center[1], center[1]))
        plt.colorbar()
        plt.title('Cartesian Image from Polar Data')
        plt.show()

    return remapped_data, remapped_std


def remove_radial_outliers(image, center, fill_value='nan', std_factor=5, plot=False, count=None):
    """
    Takes a single 2d image and identifies instances where the pixel value at any radius is an outlier. The bad pixel
    is then replaced with either np.nan or the interpolated average value.

    ARGUMENTS:

    image (2d array): 
        single image
    center (list): 
        center x value and center y value *NOTE: if center value is bad, percentage of pixels removed will be larger

    OPTIONAL ARGUMENTS:

    plot (boolean): 
        Default set to False. When true, plots the input image and the cleaned image.
    fill_value (string of either 'nan' or 'ave'): 
        Default set to 'nan'. defines whether bad pixels are replaced by np.nan or average
    std_factor (int): 
        Default set to 3. Defines standard deviation threshold for removing bad instances

    RETURNS:

    clean_image (2d array): 
        image with outliers removed
    idx_outliers (list): 
        coordinates for outlier pixels

        """
    
    image = np.array(image)

    clean_image = np.copy(image)
    ave_image, std_image = _preprocess_radial_data(image, center)
    bad_idx = np.logical_or(image >= ave_image + std_factor * std_image, image <= ave_image - std_factor * std_image)
    pct_removed = np.sum(bad_idx) / (len(image) * len(image)) * 100
    print(f"{pct_removed}% of pixels were removed.")

    if fill_value == 'nan':
        clean_image[bad_idx] = np.nan
    elif fill_value == 'ave':
        clean_image[bad_idx] = ave_image[bad_idx]

    if plot == True:
        plt.figure()
        plt.subplot(1, 3, 1)
        plt.imshow(np.log(image))
        # plt.xlim(300, 600)
        # plt.ylim(300, 600)
        plt.title("Original Image")

        plt.subplot(1, 3, 2)
        plt.imshow(np.log(ave_image))
        # plt.xlim(300, 600)
        # plt.ylim(300, 600)
        plt.title("Average Image")

        plt.subplot(1, 3, 3)
        plt.imshow(np.log(clean_image))
        # plt.xlim(300, 600)
        # plt.ylim(300, 600)
        plt.title("Cleaned Image")

        plt.tight_layout()
        plt.show()

    return clean_image, bad_idx, ave_image


def remove_radial_outliers_pool(data_array, center, plot=False):
    """
    Removes instances of outlier pixels based on the radial average of the image. Runs the hidden function _remove_radial_outliers in parallel. 
    Works by first converting an individual array to polar coordinates and remaps to create an average image. Then performs a logical check on 
    the original image compared to interpolated image. 
    
    ARGUMENTS: 
    
    data_array (3d array):
        Original data 
    center (list):
        Can either be an average center value of form [x, y] or a list of centers of form [[x1,y1], [x2, y2], ...]

    OPTIONAL ARGUMENTS: 

    plot (boolean):
        default set to False. When true, plots an example of original data, the interpolated average image, and the cleaned image

    RETURNS:

    clean_data (3d array):
        data with outliers removed

    """

    clean_data = []
    bad_idx = []
    average_data = []

    if len(center) > 2:
        print("Using all center values ")
        print("Removing radial outliers from all data")
        with concurrent.futures.ProcessPoolExecutor() as executor:
            # Zip the arrays together and submit to the executor
            results = list(executor.map(lambda args: remove_radial_outliers(*args), zip(data_array, center)))
            clean_data.append(results[0])
            bad_idx.append(results[1])
        for result in results:
            data, idx, ave = result
            clean_data.append(data)
            bad_idx.append(idx)
            average_data.append(ave)

    elif len(center) == 2:
        print("Using average center")
        print("Removing radial outliers from all data")
        with concurrent.futures.ProcessPoolExecutor() as executor:
            futures = [executor.submit(partial(remove_radial_outliers, data), center) for data in data_array]
            results = [future.result() for future in futures]

        for result in results:
            data, idx, ave = result
            clean_data.append(data)
            bad_idx.append(idx)
            average_data.append(ave)
    bad_counts = np.sum(bad_idx, axis=0)

    print(bad_counts.shape)

    if plot == True:
        plt.figure()
        plt.subplot(1, 3, 1)
        plt.imshow(data_array[0])
        # plt.xlim(300, 600)
        # plt.ylim(300, 600)
        plt.title("Original Image")

        plt.subplot(1, 3, 2)
        plt.imshow(average_data[0])
        # plt.xlim(300, 600)
        # plt.ylim(300, 600)
        plt.title("Average Image")

        plt.subplot(1, 3, 3)
        plt.imshow(clean_data[0])
        # plt.xlim(300, 600)
        # plt.ylim(300, 600)
        plt.title("Cleaned Image")

        plt.tight_layout()
        plt.show()


    return clean_data


def _azimuthal_average(image, center):
    """
    ADD DOC STRING
    """
    # Create meshgrid of coordinates
    x, y = np.indices(image.shape[:2])

    # Convert coordinates to polar coordinates
    theta = np.arctan2(y - center[1], x - center[0])
    rho = np.sqrt((x - center[0]) ** 2 + (y - center[1]) ** 2)

    # Normalize rho to [0, max_radius] for image indexing
    max_radius = np.sqrt(center[0] ** 2 + center[1] ** 2)
    # max_radius = len(image[0]) - min(center)

    rho_normalized = (rho / max_radius) * (image.shape[0] / 2)

    # Convert theta to degrees and ensure it's within [0, 360]
    theta_degrees = np.degrees(theta) % 360

    # Create polar image with correct dimensions
    polar_image = np.empty((int(max_radius), 360))
    polar_image.fill(np.nan)

    # Fill in the polar image with values from the original image
    for i in range(image.shape[0]):
        for j in range(image.shape[1]):
            polar_image[int(rho_normalized[i, j]), int(theta_degrees[i, j])] = image[i, j]

    azi_ave = np.nanmean(polar_image, axis=1)
    azi_std = np.nanstd(polar_image, axis=1)

    return azi_ave, azi_std



def get_azimuthal_average_pool(data_array, center, plot=False):
    """
    ADD DOC STRING and test
    """
    average_data = []
    std_data = []

    if len(center) > 2:
        print("Using all center values ")
        print("Removing radial outliers from all data")
        with concurrent.futures.ProcessPoolExecutor() as executor:
            # Zip the arrays together and submit to the executor
            results = list(executor.map(lambda args: _azimuthal_average(*args), zip(data_array, center)))
        for result in results:
            ave, std = result
            average_data.append(ave)
            std_data.append(std)

    elif len(center) == 2:
        print("Using average center")
        print("Removing radial outliers from all data")
        with concurrent.futures.ProcessPoolExecutor() as executor:
            futures = [executor.submit(partial(_azimuthal_average, data), center) for data in data_array]
            results = [future.result() for future in futures]

        for result in results:
            ave, std = result
            average_data.append(ave)
            std_data.append(std)

    average_data = np.array(average_data)
    std_data = np.array(std_data)

    if plot == True:
        plt.figure()
        plt.plot(average_data[0])
        plt.title("Example of Azimuthal Average")
        plt.show()

    return average_data, std_data

### PDF Generating Functions
# todo add theses functions
